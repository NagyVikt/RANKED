import requests
from bs4 import BeautifulSoup
import json
import os
import random
from urllib.parse import urljoin

# Configuration
base_url = 'https://www.svx.sk'
api_key = '4ce5d066b1d682c4fe042f95ef56fdc5'  # Set your API key here
headers = {'User-Agent': 'Mozilla/5.0'}

# Function to fetch a webpage using Scraper API
def fetch_page(url, api_key):
    payload = {
        'api_key': api_key,
        'url': url,
        'render': 'true',
        'device_type': 'desktop'
    }
    response = requests.get('http://api.scraperapi.com/', params=payload, headers=headers)
    if response.status_code != 200:
        raise Exception(f"Failed to fetch page: {response.status_code}")
    return response.text

# Function to parse subcategory URLs from the main category page
def get_subcategory_urls(category_url, api_key):
    html = fetch_page(category_url, api_key)
    soup = BeautifulSoup(html, 'html.parser')
    
    # Get all subcategories, even the collapsed ones
    subcategory_urls = []
    subcategory_tiles = soup.select('li a[href^="/lanove-prislusenstvo-a-nerezovy-program-"]')
    
    for tile in subcategory_tiles:
        href = tile['href']
        subcategory_urls.append(urljoin(base_url, href))
    
    return subcategory_urls

# Function to extract product information from a subcategory page
def get_products_from_subcategory(subcategory_url, api_key):
    html = fetch_page(subcategory_url, api_key)
    soup = BeautifulSoup(html, 'html.parser')
    
    # Find all product tiles
    products = []
    product_tiles = soup.select('div.product-item a')
    
    for product in product_tiles:
        product_name = product.get('title', '').strip()
        product_url = urljoin(base_url, product['href'])
        products.append({'name': product_name, 'url': product_url})
    
    return products

# Function to generate a random subcategory ID
def generate_subcategory_id(main_category_id):
    return f"{main_category_id}{random.randint(1, 20)}"

# Function to save product information to a JSON file
def save_product_json(product, category, subcategory, output_dir):
    product_data = {
        'name': product['name'],
        'categories': [
            {
                'id': category['id'],
                'name': category['name'],
                'slug': category['slug']
            },
            {
                'id': subcategory['id'],
                'name': subcategory['name'],
                'slug': subcategory['slug']
            }
        ]
    }
    
    # Create the directory if it doesn't exist
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # Save to a JSON file
    file_name = f"subcategories-{subcategory['slug']}.json"
    file_path = os.path.join(output_dir, file_name)
    
    with open(file_path, 'a', encoding='utf-8') as json_file:
        json.dump(product_data, json_file, ensure_ascii=False, indent=4)
        json_file.write('\n')  # For readability in a large file

# Main function to process the category
def process_category(category_url, category_info, api_key, output_dir):
    subcategory_urls = get_subcategory_urls(category_url, api_key)
    
    for subcategory_url in subcategory_urls:
        subcategory_name = subcategory_url.split('/')[-2].replace('-', ' ').title()
        subcategory_info = {
            'id': generate_subcategory_id(category_info['id']),
            'name': subcategory_name,
            'slug': subcategory_url.split('/')[-2]
        }
        
        # Get products from this subcategory
        products = get_products_from_subcategory(subcategory_url, api_key)
        
        # Save each product in this subcategory to a JSON file
        for product in products:
            save_product_json(product, category_info, subcategory_info, output_dir)

# Example usage
category_info = {
    'id': 85,
    'name': "Lanové príslušenstvo a nerezový program",
    'slug': "lanove-prislusenstvo-a-nerezovy-program"
}

# Define the category URL and output directory
category_url = "https://www.svx.sk/lanove-prislusenstvo-a-nerezovy-program-nerezovy-program/"
output_dir = "subcategories"

# Start processing the category
process_category(category_url, category_info, api_key, output_dir)  When we open this link: https://www.svx.sk/lanove-prislusenstvo-a-nerezovy-program-nerezovy-program/ than this info gets the scrapper 
    "name": "Wolf swiss quality    Montážne lepidlo (PUR) pištoľové - na Polystyrén 750ml",
 
    "categories": [
        {
            "id": 96,
            "name": "Stavebná chémia",
            "slug": "stavebna-chemia"
        },  subcategorie: { 
            "id": generate a random id for each subcategorie that is three numbers atlest or more , 
            "name": "Stavebná chémia subcategorie", 
            "slug": "stavebna-chemia-sub" 
        }    ] 
}, 